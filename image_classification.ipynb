{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "README.md                   image_folder_name.txt\r\n",
      "\u001b[34mhateful_nothateful\u001b[m\u001b[m/         mmf_hm_example.ipynb\r\n",
      "image_classification.ipynb  \u001b[34msrc\u001b[m\u001b[m/\r\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget -O Lnmwdnq3YcF7F3YsJncp.zip --no-check-certificate --no-proxy \"https://drivendata-competition-fb-hateful-memes-data.s3.amazonaws.com/XjiOc5ycDBRRNwbhRlgH.zip?AWSAccessKeyId=AKIARVBOBDCY4MWEDJKS&Signature=vwrcLD1%2FgzoI%2B%2Be4TlMITuWphVg%3D&Expires=1607484815\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !unzip -q -P EWryfbZyNviilcDF Lnmwdnq3YcF7F3YsJncp.zip -d data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 120\r\n",
      "-rw-r--r--  1 gramadurai  staff    141 Nov 27 19:00 README.md\r\n",
      "-rw-r--r--@ 1 gramadurai  staff  20461 Dec  5 21:01 mmf_hm_example.ipynb\r\n",
      "drwxr-xr-x  6 gramadurai  staff    192 Dec  5 22:09 \u001b[34msrc\u001b[m\u001b[m/\r\n",
      "drwxr-xr-x  8 gramadurai  staff    256 Dec  5 23:24 \u001b[34mhateful_nothateful\u001b[m\u001b[m/\r\n",
      "-rw-r--r--  1 gramadurai  staff     85 Dec  5 23:24 image_folder_name.txt\r\n",
      "-rw-r--r--  1 gramadurai  staff  30221 Dec  5 23:53 image_classification.ipynb\r\n"
     ]
    }
   ],
   "source": [
    "ls -lrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models.image_models.load_config import config_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DatasetConfig]\r\n",
      "base_path = \"hateful_nothateful\"\r\n",
      "train_path = \"hateful_nothateful/training\"\r\n",
      "validation_path = \"hateful_nothateful/validation\"\r\n",
      "test_path = \"hateful_nothateful/testing\"\r\n",
      "\r\n",
      "[BaseConfig]\r\n",
      "classes = [\"hateful\", \"not_hateful\"]\r\n",
      "\r\n",
      "\r\n",
      "[ImageModelConfig]\r\n",
      "[Resnet152]\r\n",
      "lr = 1e-4\r\n",
      "batch_size = 10\r\n",
      "num_epochs = 50\r\n",
      "trained_model_save_path = \"trained_models/resnet152.model\"\r\n"
     ]
    }
   ],
   "source": [
    "cat src/config/model_config.ini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_file = \"src/config/model_config.ini\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = config_loader(config_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'DatasetConfig': {'base_path': 'hateful_nothateful',\n",
       "  'train_path': 'hateful_nothateful/training',\n",
       "  'validation_path': 'hateful_nothateful/validation',\n",
       "  'test_path': 'hateful_nothateful/testing'},\n",
       " 'BaseConfig': {'classes': ['hateful', 'not_hateful']},\n",
       " 'ImageModelConfig': {},\n",
       " 'Resnet152': {'lr': 0.0001,\n",
       "  'batch_size': 10,\n",
       "  'num_epochs': 50,\n",
       "  'trained_model_save_path': 'trained_models/resnet152.model'}}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = config['DatasetConfig']['base_path']\n",
    "train_path = config['DatasetConfig']['train_path']\n",
    "validation_path = config['DatasetConfig']['validation_path']\n",
    "test_path = config['DatasetConfig']['test_path']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_src_path = \"data/data\"\n",
    "data_src_path = \"../Facebook_meme_dataset/dataHatefulMemes/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../Facebook_meme_dataset/dataHatefulMemes/\r\n"
     ]
    }
   ],
   "source": [
    "!echo $data_src_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# !python3 src/data_preprocessing/prepare_dataset.py -s $data_src_path -d $base_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "README.md                   image_folder_name.txt\r\n",
      "\u001b[34mhateful_nothateful\u001b[m\u001b[m/         mmf_hm_example.ipynb\r\n",
      "image_classification.ipynb  \u001b[34msrc\u001b[m\u001b[m/\r\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01235.png\r\n",
      "01247.png\r\n",
      "01256.png\r\n",
      "01258.png\r\n",
      "01269.png\r\n",
      "01295.png\r\n",
      "01349.png\r\n",
      "01395.png\r\n",
      "01436.png\r\n",
      "01467.png\r\n"
     ]
    }
   ],
   "source": [
    "ls hateful_nothateful/training/hateful/ | head -n 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train RESNET152 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "####### Model Parameters #######\n",
      "Learning_rate = 0.0001\n",
      "batch_size = 10\n",
      "num_epochs = 50\n",
      "####### -------------- #######\n"
     ]
    }
   ],
   "source": [
    "## SETUP PARAMS\n",
    "\n",
    "lr = config['Resnet152']['lr']\n",
    "batch_size = config['Resnet152']['batch_size']\n",
    "num_epochs = config['Resnet152']['num_epochs']\n",
    "\n",
    "## Parameters\n",
    "print(\"####### Model Parameters #######\")\n",
    "print (f\"Learning_rate = {lr}\")\n",
    "print (f\"batch_size = {batch_size}\")\n",
    "print (f\"num_epochs = {num_epochs}\")\n",
    "\n",
    "print(\"####### -------------- #######\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hateful_nothateful/training'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imutils import paths\n",
    "paths.list_images(train_path)\n",
    "totalTrain = len(list(paths.list_images(train_path)))\n",
    "totalVal = len(list(paths.list_images(validation_path)))\n",
    "totalTest = len(list(paths.list_images(test_path)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "540"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "totalTest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8500"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "totalTrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "totalVal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing the training data augmentation object\n",
      "initializing the val data augmentation object\n",
      "initializing the training generator\n",
      "Found 8500 images belonging to 2 classes.\n",
      "initializing the val generator\n",
      "Found 500 images belonging to 2 classes.\n",
      "initializing the testing generator\n",
      "Found 540 images belonging to 2 classes.\n",
      "[INFO] preparing model...\n",
      "[INFO] training model...\n",
      "Epoch 1/5\n",
      "441/850 [==============>...............] - ETA: 9:52 - loss: 0.8099 - accuracy: 0.5844"
     ]
    }
   ],
   "source": [
    "# based on https://www.pyimagesearch.com/2020/04/27/fine-tuning-resnet-with-keras-tensorflow-and-deep-learning/\n",
    "import matplotlib\n",
    "matplotlib.use(\"Agg\")\n",
    "# import the necessary packages\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.layers import AveragePooling2D\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.applications import ResNet152\n",
    "from sklearn.metrics import classification_report\n",
    "from imutils import paths\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import argparse\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.keras.engine import data_adapter\n",
    "\n",
    "# let me load the data in a different manner\n",
    "# image_path = \"/Users/andrei/Ryerson/neuralNet_EE8204/codeTests/resnet/hateful_nothateful_images/validation/hateful/95640.png\"\n",
    "# image = load_img(image_path, target_size=(224, 224))\n",
    "# input_arr = img_to_array(image)\n",
    "# #input_arr = np.array([input_arr])\n",
    "# print(input_arr.shape)\n",
    "# exit()\n",
    "# construct the argument parser and parse the arguments\n",
    "#ap = argparse.ArgumentParser()\n",
    "#ap.add_argument(\"-p\", \"--plot\", type=str, default=\"plot.png\",\n",
    "#                help=\"path to output loss/accuracy plot\")\n",
    "#args = vars(ap.parse_args())\n",
    "# determine the total number of image paths in training, validation,\n",
    "# and testing directories\n",
    "totalTrain = len(list(paths.list_images(train_path)))\n",
    "totalVal = len(list(paths.list_images(validation_path)))\n",
    "totalTest = len(list(paths.list_images(test_path)))\n",
    "\n",
    "print(\"initializing the training data augmentation object\")\n",
    "# initialize the training training data augmentation object\n",
    "trainAug = ImageDataGenerator(\n",
    "    rotation_range=25,\n",
    "    zoom_range=0.1,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    shear_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode=\"nearest\")\n",
    "# initialize the validation/testing data augmentation object (which\n",
    "# we'll be adding mean subtraction to)\n",
    "print(\"initializing the val data augmentation object\")\n",
    "valAug = ImageDataGenerator()\n",
    "# define the ImageNet mean subtraction (in RGB order) and set the\n",
    "# the mean subtraction value for each of the data augmentation\n",
    "# objects\n",
    "mean = np.array([123.68, 116.779, 103.939], dtype=\"float32\")\n",
    "trainAug.mean = mean\n",
    "valAug.mean = mean\n",
    "\n",
    "\n",
    "# initialize the training generator\n",
    "print(\"initializing the training generator\")\n",
    "trainGen = trainAug.flow_from_directory(\n",
    "    train_path,\n",
    "    class_mode=\"categorical\",\n",
    "    target_size=(224, 224),\n",
    "    color_mode=\"rgb\",\n",
    "    shuffle=True,\n",
    "    batch_size=batch_size)\n",
    "# by the looks of it the train gnerator returns a dictinaryiterator [x,y] whre x is the batch and\n",
    "# y is the labels\n",
    "# print(len(trainGen.next()[1]))\n",
    "# initialize the validation generator\n",
    "print(\"initializing the val generator\")\n",
    "valGen = valAug.flow_from_directory(\n",
    "    validation_path,\n",
    "    class_mode=\"categorical\",\n",
    "    target_size=(224, 224),\n",
    "    color_mode=\"rgb\",\n",
    "    shuffle=False,\n",
    "    batch_size=batch_size)\n",
    "# initialize the testing generator\n",
    "print(\"initializing the testing generator\")\n",
    "testGen = valAug.flow_from_directory(\n",
    "    test_path,\n",
    "    class_mode=\"categorical\",\n",
    "    target_size=(224, 224),\n",
    "    color_mode=\"rgb\",\n",
    "    shuffle=False,\n",
    "    batch_size=1)\n",
    "\n",
    "\n",
    "# load the ResNet-50 network, ensuring the head FC layer sets are left\n",
    "# off\n",
    "print(\"[INFO] preparing model...\")\n",
    "baseModel = ResNet152(weights=\"imagenet\", include_top=False,\n",
    "                      input_tensor=Input(shape=(224, 224, 3)))\n",
    "# construct the head of the model that will be placed on top of the\n",
    "# the base model\n",
    "headModel = baseModel.output\n",
    "headModel = AveragePooling2D(pool_size=(7, 7))(headModel)\n",
    "headModel = Flatten(name=\"flatten\")(headModel)\n",
    "\n",
    "headModel = Dense(256, activation=\"relu\")(headModel)\n",
    "headModel = Dropout(0.5)(headModel)\n",
    "\n",
    "headModel = Dense(len(config['BaseConfig']['classes']), activation=\"softmax\")(headModel)  # this is my softmax layer for output\n",
    "# place the head FC model on top of the base model (this will become\n",
    "# the actual model we will train)\n",
    "model = Model(inputs=baseModel.input, outputs=headModel)\n",
    "# loop over all layers in the base model and freeze them so they will\n",
    "# *not* be updated during the training process\n",
    "\n",
    "for layer in baseModel.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "    # compile the model\n",
    "opt = Adam(lr=lr, decay=lr / num_epochs)\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=opt,\n",
    "              metrics=[\"accuracy\"])\n",
    "# train the model\n",
    "print(\"[INFO] training model...\")\n",
    "H = model.fit(\n",
    "    x=trainGen,\n",
    "    steps_per_epoch=totalTrain // batch_size,\n",
    "    validation_data=valGen,\n",
    "    validation_steps=totalVal // batch_size,\n",
    "    epochs=5)\n",
    "\n",
    "# print(model.summary())\n",
    "#tf.keras.experimental.export_saved_model(model, config.MODEL_PATH)\n",
    "model.save(\"hateful_img_meme.model\", save_format=\"h5\")\n",
    "print(\"finished saving model\")\n",
    "# exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
